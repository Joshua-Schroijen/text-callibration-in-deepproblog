\cite{guo2017calibration} posited that in recent times a trade-off might be emerging in advanced neural network design between model accuracy on the one hand and model calibratedness on the other hand. If this principle extended to DeepProbLog models we would expect to observe the following phenomena:
\begin{enumerate}
  \item A DeepProbLog model would be naturally uncalibrated or undercalibrated, i.e. its calibratedness could be increased through intervention
  \item Calibrating a DeepProbLog model would increase the model's calibratedness
  \item Calibrating a DeepProbLog model would decrease the model's accuracy at the same time
  \item In noisy environments a calibration intervention would amplify aforementioned effects
\end{enumerate}
The observations we made in our experiments as laid out in chapter \ref{results_chapter} in fact demonstrate these phenomena. The extent to which they appear is not dramatic, but at single digit percentages is nevertheless still substantial. Simple post training (temperature scaling) calibration appears to be the best method (both in quantitative effectiveness and in computational cost) to increase calibratedness.
In conclusion, DeepProbLog models' calibratedness can be improved through simple post training temperature scaling calibration, but at a direct between 1-for-1 to 2-for-1 cost to their query answering accuracy. It is all by all remarkable that DeepProbLog models are naturally undercalibrated, as by default DeepProbLog minimizes model cross-entropy loss during training. That should imply the model converging to an optimal probabilistic model or in other words the model becoming increasingly calibrated. Studying DeepProbLog training and model expressivity in more depth could therefore prove an interesting avenue for further research.