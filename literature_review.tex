\section{Review of the calibration problem and methods}
In this section we will summarize \cite{guo2017calibration}'s findings and propositions on the topic of neural network calibration.

\subsection{The general problem of neural network model calibration degradation}
\cite{guo2017calibration} discovered that they could not confirm \cite{niculescu2005predicting}'s observation that neural networks (for binary classification) were typically well-calibrated for the latest generation of deep neural network models. \cite{lecun1998gradient}'s 5-layer LeNet was compared to \cite{he2016deep}'s 110 layer ResNet on the CIFAR-100 dataset. This comparison is visualized in figure \ref{fig:lenet_vs_resnet_calibration_guo_et_al}, where the top row shows prediction confidence histograms and the bottom row shows reliability diagrams (RDs). RDs show a model's accuracy as a function of its confidence. A perfectly callibrated model has a 45Â° angled line as its RD. Figure \ref{fig:lenet_vs_resnet_calibration_guo_et_al} shows a striking overconfidence of the ResNet on CIFAR-100 while showing the LeNet has an almost perfect RD on it. \cite{guo2017calibration} thus proposes that the modern ResNet has gained in accuracy over the older LeNet by, through some mechanism, sacrificing calibration. Through abductive reasoning \cite{guo2017calibration} hypothesizes and substantiates that this is a general and explainable evolutionairy trend in artificial neural network R\&D. 

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\linewidth]{images/lenet_vs_resnet_calibration_guo_et_al.jpg}
  \caption[5-layer LeNet's vs. 110-layer ResNet's calibration.]{5-layer LeNet (left) vs. 110-layer ResNet (right) calibration.}
  \label{fig:lenet_vs_resnet_calibration_guo_et_al}
  \source{\cite{guo2017calibration}}
\end{figure}

%...
%This formula $f(x) = x^2$ is an example.
%...

\section{Review of applications of interest}
In this work we want to evaluate and analyze the impact of calibration on representative DeepProbLog use-cases where it presents a considerable issue. Unfortunately, these use-cases are not a given. To find and choose some, we first required that:
\begin{itemize}
  \item using PLP with neural predicates to tackle it is appropriate
  \item it is widely studied in neuro-symbolic integration research
  \item there is room to improve it through callibrating (parts of) models
\end{itemize}
If the first and third criterions are not met, there is no reason to use DeepProbLog and/or calibration and the knowledge we'd gain and features we'd create would not necessarily be relevant to our target audience. That's why we disregard most well-known AI toy problems such as playing chess, the N-queens problem and MNIST digit recognition and we start with reservations about using the DeepProbLog demonstration problems showcased by \cite{manhaeve2018deepproblog}. But we do require widely used challenges like the general AI toy problems so that our work's properties and performance can be easily compared to those of other approaches (\cite{russell2002artificial}), hence our second criterion. \par
We then performed a shallow literature scan of neuro-symbolic integration to find recurring themes and toy problems in this field of research. The scientific literature search engines Google Scholar (by Google) and Limo (by KU Leuven) were used to search for papers containing the keywords "neuro", "symbolic" and "integration" simultaneously. 63 random papers were chosen from the results. A breakdown of the problem categories these papers work in is given in table \ref{subject_breakdown}. Papers can work in multiple categories, the count column shows how many work in the category and the \% column shows what percentage of the 63 work in it.
\begin{table}[!htbp]
\centering
\begin{tabular}{ |c|c|c| }
 \hline
 \textbf{Category} & \textbf{Count} & \textbf{\%} \\
 \hline
 Acoustic information processing & 1 & 1.59\% \\
 \hline
 Actuarial science & 2 & 3.17\% \\
 \hline
 Natural sciences modelling & 2 & 3.17\% \\
 \hline
 Control theory & 4 & 6.35\% \\
 \hline
 Fraud detection & 1 & 1.59\% \\
 \hline
 Natural language processing & 7 & 11.11\% \\
 \hline
 Numerical analysis & 1 & 1.59\% \\
 \hline
 Robotics & 2 & 3.17\% \\
 \hline
 Social \& political sciences & 2 & 3.17\% \\
 \hline
 Symbolic knowledge \& structured data processing & 33 & 52.38\%  \\
 \hline
 Visual information processing & 16 & 25.40\%  \\
 \hline
\end{tabular}
\caption{Subfield breakdown of neuro-symbolic integration research}
\label{subject_breakdown}
\end{table}