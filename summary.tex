In recent years, the field of machine learning effectively leveraged increased computing power. Through increasingly complex topologies, performance breakthroughs were achieved in image classification, machine translation, text and image generation and other applications. However, it was unfortunately observed that this generally came at a large expense of network calibration or the confidence networks have in their predictions. This presents a dilemma to the subfield of neuro-symbolic integration for probabilistic inference, where ideally neural networks' excellent learning capabilities are combined with necessarily sound calibration. We implement temperature scaling calibration schemes in representative applications of the DeepProbLog probabilistic logic programming language and measure differences in model performance and calibratedness. We investigate whether model calibration is necessary or beneficial in this context. We conclude that simple post model training calibration can significantly improve model calibratedness but that this comes at a significant cost to deterministic model query answering accuracy.